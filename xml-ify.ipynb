{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom\n",
    "import xml\n",
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "import PyPDF2 as ppdf\n",
    "import string\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from ratelimit import limits, sleep_and_retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vars\n",
    "URL = \"https://e-dictionary.ilrdf.org.tw/wsReDictionary.htm\"\n",
    "\n",
    "original_dict = {\n",
    "    2: 'Amis',\n",
    "    6: 'Atayal',\n",
    "    24: 'Paiwan',\n",
    "    22: 'Bunun',\n",
    "    38: 'Puyma',\n",
    "    28: 'Rukai',\n",
    "    35: 'Tsou',\n",
    "    13: 'Saisiyat',\n",
    "    42: 'Yami',\n",
    "    14: 'Thao',\n",
    "    34: 'Kavalan',\n",
    "    33: 'Truku',\n",
    "    43: 'Sakizaya',\n",
    "    16: 'Seediq',\n",
    "    37: 'Saaroa',\n",
    "    36: 'Kanakanavu'\n",
    "}\n",
    "\n",
    "# Create a new dictionary with keys and values swapped\n",
    "TRIBES = {v: k for k, v in original_dict.items()}\n",
    "NAMES = sorted([\n",
    "    'Amis',\n",
    "    'Atayal',\n",
    "    'Paiwan',\n",
    "    'Bunun',\n",
    "    'Puyma',\n",
    "    'Rukai',\n",
    "    'Tsou',\n",
    "    'Saisiyat',\n",
    "    'Yami',\n",
    "    'Thao',\n",
    "    'Kavalan',\n",
    "    'Truku',\n",
    "    'Sakizaya',\n",
    "    'Seediq',\n",
    "    'Saaroa',\n",
    "    'Kanakanavu'\n",
    "])\n",
    "\n",
    "INTERVAL = 500\n",
    "\n",
    "RATE_LIMIT = 25\n",
    "RATE_PERIOD = 1\n",
    "\n",
    "NAME_TO_IDX = {name: i for i, name in enumerate(NAMES)}\n",
    "\n",
    "PICKLE_FOLDER = '.PickleScrapes/'\n",
    "\n",
    "TRIBE_STR_TO_ISO = {\n",
    "    'Amis': 'ami',\n",
    "    'Atayal': 'tay',\n",
    "    'Paiwan': 'pwn',\n",
    "    'Bunun': 'bnn',\n",
    "    'Puyma': 'pyu',\n",
    "    'Rukai': 'dru',\n",
    "    'Tsou': 'tsu',\n",
    "    'Saisiyat': 'xsy',\n",
    "    'Yami': 'tao',\n",
    "    'Thao': 'ssf',\n",
    "    'Kavalan': 'ckv',\n",
    "    'Truku': 'trv',\n",
    "    'Sakizaya': 'ais',\n",
    "    'Seediq': 'sdq',\n",
    "    'Saaroa': 'sxr',\n",
    "    'Kanakanavu': 'xnb'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPickles(tribe:str):\n",
    "    ckpt_good, ckpt_fail = None, None\n",
    "\n",
    "    with open(os.path.join(PICKLE_FOLDER, tribe, tribe + '_ckpt_END.pkl'), 'rb') as f: \n",
    "        ckpt_good = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(PICKLE_FOLDER, tribe, tribe + '_fails_END.pkl'), 'rb') as f: \n",
    "        ckpt_fail = pickle.load(f)\n",
    "\n",
    "    return ckpt_good, ckpt_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDataRatios():\n",
    "    for name in NAMES:\n",
    "        g, f = getPickles(name)\n",
    "        ratio = (len(g) - len(f)) / len(g)\n",
    "        print(f'{name[0:6]}\\t{ratio:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLists(tribe: str) -> (list, list, list):\n",
    "    all, bad = getPickles(tribe)\n",
    "\n",
    "    goodwords = []\n",
    "    for q, w in all.items():\n",
    "        if w != 'FAIL':\n",
    "            goodwords.append(q)\n",
    "\n",
    "    assert len(goodwords) + len(bad) == len(all)\n",
    "\n",
    "    singles, multi = [], []\n",
    "    for w in goodwords:\n",
    "        query = all[w]\n",
    "        if isinstance(query, list):\n",
    "            multi.append(query)\n",
    "        elif isinstance(query, dict):\n",
    "            singles.append(query)\n",
    "\n",
    "    return (goodwords, singles, multi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleHelper(sent):\n",
    "    # check all key components\n",
    "    for key in ['Original', 'Chinese', 'File']:\n",
    "        if key not in sent.keys():\n",
    "            return False\n",
    "\n",
    "    # extract text\n",
    "    audio = sent['File']\n",
    "    fr_tx = sent['Original']\n",
    "    cn_tx = sent['Chinese']\n",
    "    return [fr_tx, cn_tx, audio]\n",
    "\n",
    "def createElemHelp(tr, count, r):\n",
    "    # xml setup\n",
    "    s = ET.Element('S')\n",
    "    s.set('id', str(tr) + \"_\" + str(count))\n",
    "    count += 1\n",
    "\n",
    "    form = ET.SubElement(s, 'FORM') # sentence\n",
    "    tl = ET.SubElement(s, 'TRANSL') # translation\n",
    "    tl.set('xml:lang', 'zho')\n",
    "    audio = ET.SubElement(s, 'AUDIO') # audio link\n",
    "\n",
    "    tl.text = r[1]\n",
    "    form.text = r[0]\n",
    "\n",
    "    # yami will produce a list so pick 1st choice\n",
    "    if isinstance(r[2], list):\n",
    "        r[2] = r[2][0]\n",
    "    audio.set('url', r[2]['Path'])\n",
    "\n",
    "    return s, count, form.text\n",
    "\n",
    "def wrapperXML(sent, root, count, seen):\n",
    "    # process every request thru same pipeline\n",
    "    if (r := handleHelper(sent)):\n",
    "        s, count, te= createElemHelp(tr, count, r)\n",
    "        # memoization\n",
    "        if te in seen:\n",
    "            return count-1\n",
    "        else:\n",
    "            seen[te] = ''\n",
    "            root.append(s)  \n",
    "    return count\n",
    "\n",
    "def handleExplanation(expl, root, tr: str, count: int, seen): # assume expl is dict\n",
    "    # expl is dict\n",
    "    if isinstance(expl, dict):\n",
    "        if 'Sentence' not in expl.keys(): \n",
    "            return count, seen\n",
    "        sent = expl['Sentence']\n",
    "\n",
    "        # dict case\n",
    "        if isinstance(sent, dict):        \n",
    "            count = wrapperXML(sent, root, count, seen)\n",
    "        # list case\n",
    "        elif isinstance(sent, list):\n",
    "            for n in sent:\n",
    "                count = wrapperXML(n, root, count, seen)\n",
    "\n",
    "    # expl is list\n",
    "    elif isinstance(expl, list):\n",
    "        for explan in expl:\n",
    "            if 'Sentence' not in explan.keys(): \n",
    "                continue\n",
    "            sent = explan['Sentence']\n",
    "\n",
    "            # dict case\n",
    "            if isinstance(sent, dict):        \n",
    "                count = wrapperXML(sent, root, count, seen)\n",
    "            # list case\n",
    "            elif isinstance(sent, list):\n",
    "                for n in sent:\n",
    "                    count = wrapperXML(n, root, count, seen)\n",
    "    return count, seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amis\t5850\t5482\t368\n",
      "Atayal\t5646\t6393\t-747\n",
      "Bunun\t5547\t8714\t-3167\n",
      "Kanaka\t4008\t5639\t-1631\n",
      "Kavala\t6670\t8241\t-1571\n",
      "Paiwan\t5505\t5365\t140\n",
      "Puyma\t7359\t7073\t286\n",
      "Rukai\t10683\t10454\t229\n",
      "Saaroa\t4425\t4115\t310\n",
      "Saisiy\t5012\t6102\t-1090\n",
      "Sakiza\t5703\t5360\t343\n",
      "Seediq\t5470\t5478\t-8\n",
      "Thao\t3693\t6419\t-2726\n",
      "Truku\t31294\t4682\t26612\n",
      "Tsou\t2836\t2884\t-48\n",
      "Yami\t6320\t6437\t-117\n"
     ]
    }
   ],
   "source": [
    "for tr in NAMES:\n",
    "    # XML setup\n",
    "    root = ET.Element(\"TEXT\")\n",
    "    root.set(\"id\", tr)\n",
    "    root.set(\"citation\", \"財團法人原住民族語言研究發展基金會. (2021). ILRDF Webservice Dictionary. Retrieved June 25, 2024, from https://e-dictionary.ilrdf.org.tw/wsReDictionary.htm\")\n",
    "    root.set(\"copyright\", \"Creative Commons\")\n",
    "    root.set(\"xml:lang\", TRIBE_STR_TO_ISO[tr])\n",
    "\n",
    "    # make lists and init vars\n",
    "    gw, singles, multis = makeLists(tr)\n",
    "    count = 0\n",
    "    seen = {}\n",
    "\n",
    "    # iterate thru entries\n",
    "    for w in singles:\n",
    "        if 'Explanation' in w.keys():\n",
    "            count, seen = handleExplanation(w['Explanation'], root, tr, count, seen)\n",
    "\n",
    "    for ww in multis:\n",
    "        for w in ww:\n",
    "            if 'Explanation' in w.keys():\n",
    "                count, seen = handleExplanation(w['Explanation'], root, tr, count, seen)\n",
    "\n",
    "    # print error margins\n",
    "    g, f = getPickles(tr)\n",
    "    g = len(g)\n",
    "    print(f\"{tr[0:6]}\\t{g}\\t{count}\\t{g - count}\")\n",
    "\n",
    "    # convert to str\n",
    "    tree = ET.ElementTree(root)\n",
    "    xml_str = ET.tostring(root, encoding='utf-8')\n",
    "\n",
    "    # convert str to pretty using minidom\n",
    "    dom = xml.dom.minidom.parseString(xml_str)\n",
    "    pretty_xml_str = dom.toprettyxml(indent=\"  \")\n",
    "\n",
    "    # make path and mkdir\n",
    "    dir = os.path.join(os.getcwd(), '.PanglossXML', tr)\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    f = os.path.join(dir, f\"{tr}.xml\")\n",
    "    with open(f, 'w', encoding='utf-8') as file:\n",
    "        file.write(pretty_xml_str)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for debug purposes. change tr to target a tribe and check the output\n",
    "# tr = 'Yami' # set to your tribe you want to debug\n",
    "# goodwords, singles, multis = makeLists(tr)\n",
    "\n",
    "# root = ET.Element(\"TEXT\")\n",
    "# root.set(\"xml:lang\", TRIBE_STR_TO_ISO[tr])\n",
    "# root.set(\"id\", tr) \n",
    "\n",
    "# count = 0\n",
    "# seen = {}\n",
    "# for w in singles:\n",
    "#     count, seen = handleExplanation(w['Explanation'], root, tr, count, seen)\n",
    "\n",
    "# for ww in multis:\n",
    "#     for w in ww:\n",
    "#         count, seen = handleExplanation(w['Explanation'], root, tr, count, seen)\n",
    "\n",
    "# # print error margins\n",
    "# g, w = getPickles(tr)\n",
    "# l = len(g) + len(w)\n",
    "# print(f\"{tr[0:6]}\\t{l}\\t{count}\\t{l - count} unaccounted\")\n",
    "\n",
    "# tree = ET.ElementTree(root)\n",
    "\n",
    "# # convert to str\n",
    "# xml_str = ET.tostring(root, encoding='utf-8')\n",
    "\n",
    "# # convert str to pretty using minidom\n",
    "# dom = xml.dom.minidom.parseString(xml_str)\n",
    "# pretty_xml_str = dom.toprettyxml(indent=\"  \")\n",
    "\n",
    "# # print\n",
    "# print(pretty_xml_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
