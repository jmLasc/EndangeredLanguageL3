{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml\n",
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "import PyPDF2 as ppdf\n",
    "import string\n",
    "import pickle\n",
    "from ratelimit import limits, sleep_and_retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vars\n",
    "URL = \"https://e-dictionary.ilrdf.org.tw/wsReDictionary.htm\"\n",
    "\n",
    "original_dict = {\n",
    "    2: 'Amis',\n",
    "    6: 'Atayal',\n",
    "    24: 'Paiwan',\n",
    "    22: 'Bunun',\n",
    "    38: 'Puyma',\n",
    "    28: 'Rukai',\n",
    "    35: 'Tsou',\n",
    "    13: 'Saisiyat',\n",
    "    42: 'Yami',\n",
    "    14: 'Thao',\n",
    "    34: 'Kavalan',\n",
    "    33: 'Truku',\n",
    "    43: 'Sakizaya',\n",
    "    16: 'Seediq',\n",
    "    37: 'Saaroa',\n",
    "    36: 'Kanakanavu'\n",
    "}\n",
    "\n",
    "# Create a new dictionary with keys and values swapped\n",
    "TRIBES = {v: k for k, v in original_dict.items()}\n",
    "NAMES = sorted([\n",
    "    'Amis',\n",
    "    'Atayal',\n",
    "    'Paiwan',\n",
    "    'Bunun',\n",
    "    'Puyma',\n",
    "    'Rukai',\n",
    "    'Tsou',\n",
    "    'Saisiyat',\n",
    "    'Yami',\n",
    "    'Thao',\n",
    "    'Kavalan',\n",
    "    'Truku',\n",
    "    'Sakizaya',\n",
    "    'Seediq',\n",
    "    'Saaroa',\n",
    "    'Kanakanavu'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rate vars\n",
    "# this mostly shouldn't matter since API times are already slow-ish\n",
    "RATE_LIMIT = 25\n",
    "RATE_PERIOD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWords(index): # scrape, do once -> provides wordlist\n",
    "    # Get path\n",
    "    folders = [folder for folder in os.listdir(os.getcwd()) if os.path.isdir(folder) and not folder[0] == \".\"]\n",
    "    folder = folders[index] # index\n",
    "    get_pdf = [file for file in os.listdir(folder)]\n",
    "    get_pdf = [file for file in get_pdf if re.search(r\".*\\.pdf\", file.lower())]\n",
    "    filepath = os.path.join(os.getcwd(), folder, get_pdf[0])\n",
    "\n",
    "    # Open it + scrape\n",
    "    all_tx = []\n",
    "    with open(filepath, 'rb') as f:\n",
    "        reader = ppdf.PdfReader(f)\n",
    "\n",
    "        for num in range(len(reader.pages)):\n",
    "            page = reader.pages[num]\n",
    "            all_tx.append(page.extract_text())\n",
    "\n",
    "    # Get words\n",
    "    fullstring = \"\"\n",
    "    for line in all_tx:\n",
    "        fullstring += line\n",
    "    \n",
    "    # Split + identify words\n",
    "    sep = fullstring.split(\"\\n\")\n",
    "    words = [word for word in sep if \"â˜…\" in word]\n",
    "    return [re.search(r\"^([a-z\\^A-Z']+)\", word).group(1) for word in words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @sleep_and_retry -- should not matter unless ratelimiting, if so uncomment\n",
    "# @limits(calls=RATE_LIMIT, period=RATE_PERIOD)\n",
    "def getData(tribeName, qw):\n",
    "    ask = {\n",
    "        \"FMT\": 1,\n",
    "        \"account\": \"E202403005\",\n",
    "        \"TribesCode\": TRIBES[tribeName],\n",
    "        \"qw\": qw\n",
    "    }\n",
    "\n",
    "    jsn_response = requests.post(URL, data=ask)\n",
    "    text = json.loads(jsn_response.text)\n",
    "    try:\n",
    "        assert jsn_response.status_code == 200\n",
    "        return text[\"GenericData\"]['DATA']\n",
    "    except:\n",
    "        return \"FAIL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSentences(entry): # helper for processRequest\n",
    "    word = entry[\"Name\"]\n",
    "    check = entry['Explanation']\n",
    "    fr, zh = '', ''\n",
    "\n",
    "    try:\n",
    "        if isinstance(check, list):\n",
    "            check = check[0] # it works\n",
    "            if isinstance(check['Sentence'], dict):\n",
    "                fr = check['Sentence']['Original']\n",
    "                zh = check['Sentence']['Chinese']\n",
    "\n",
    "            elif isinstance(check['Sentence'], list):\n",
    "                fr = check['Sentence'][0]['Original']\n",
    "                zh = check['Sentence'][0]['Chinese']\n",
    "        \n",
    "        elif isinstance(check, dict):\n",
    "            if isinstance(check['Sentence'], dict):\n",
    "                fr = check['Sentence']['Original']\n",
    "                zh = check['Sentence']['Chinese']\n",
    "\n",
    "            elif isinstance(check['Sentence'], list):\n",
    "                fr = check['Sentence'][0]['Original']\n",
    "                zh = check['Sentence'][0]['Chinese']\n",
    "        return {word: (fr, zh)}\n",
    "    except:\n",
    "        return \"FAIL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRequest(response): # response into dict of {word: (fr, zh)}\n",
    "    ret = {}\n",
    "    fails = []\n",
    "    if isinstance(response, list): # multiple entries\n",
    "        for i, entry in enumerate(response):\n",
    "            result = extractSentences(entry)\n",
    "            word = entry[\"Name\"]\n",
    "            if result == \"FAIL\":\n",
    "                print(word + \" has failed in extraction.\") # comment out if annoying \n",
    "                fails.append(word)\n",
    "            else:\n",
    "                ret.update(result)\n",
    "\n",
    "    elif isinstance(response, dict): # only 1 entry\n",
    "        result = extractSentences(response)\n",
    "        word = response[\"Name\"]\n",
    "        if result == \"FAIL\":\n",
    "            print(word + \" has failed in extraction.\") # comment out if annoying \n",
    "            fails.append(word)\n",
    "        else:\n",
    "            ret.update(result)\n",
    "        \n",
    "    return ret, fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch wordlist\n",
    "words = set(getWords(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at iteration 0: kalona\n",
      "Error occurred at iteration 2: maropayay\n"
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "word_sent_dict = {}\n",
    "fails = []\n",
    "seen = set()\n",
    "for i, query in enumerate(words):\n",
    "    try:\n",
    "        if query in set():\n",
    "            pass\n",
    "        else:\n",
    "            seen.add(query)\n",
    "            response = getData('Amis', query)\n",
    "            if response == 'FAIL':\n",
    "                fails.append(query)\n",
    "                pass\n",
    "\n",
    "            result, bad = processRequest(response)\n",
    "            fails.extend(bad)\n",
    "            if result == \"FAIL\":\n",
    "                fails.append(query)\n",
    "                pass\n",
    "\n",
    "            word_sent_dict.update(result)\n",
    "\n",
    "        if i % 500 == 0 or i == len(words) - 1:\n",
    "            with open('Amis_ckpt_{0}.pkl'.format(i), 'w', encoding='utf8') as f:\n",
    "                pickle.dump(word_sent_dict, f)\n",
    "            with open('Amis_fails_{0}.pkl'.format(i), 'w', encoding='utf8') as f:\n",
    "                pickle.dump(fails, f)\n",
    "    except:\n",
    "        print(f\"Error occurred at iteration {i}: {query}\")\n",
    "\n",
    "with open('Amis_ckpt.pkl', 'wb') as f:\n",
    "    pickle.dump(word_sent_dict, f)\n",
    "with open('Amis_fails_1.pkl', 'wb') as f:\n",
    "    pickle.dump(fails, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 170m runtime for 6k words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open archived files\n",
    "wsd_pickle = None\n",
    "with open('Amis_ckpt.pkl', 'rb') as f:\n",
    "    wsd_pickle = pickle.load(f)\n",
    "\n",
    "notgood = None\n",
    "with open('Amis_fails_1.pkl', 'rb') as f:\n",
    "    notgood = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML setup\n",
    "root = ET.Element(\"TEXT\")\n",
    "root.set(\"xml:lang\", \"fr\")\n",
    "root.set(\"id\", 'Amis') # change second arg to lang name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML adding\n",
    "for i, (word, sentpair) in enumerate(wsd_pickle.items()):\n",
    "    zh = sentpair[1]\n",
    "    fr = sentpair[0]\n",
    "\n",
    "    name = 'Amis' + str(i) # change tribename\n",
    "    s = ET.SubElement(root, 'S')\n",
    "    s.set('id', name)\n",
    "\n",
    "    form = ET.SubElement(s, \"FORM\")\n",
    "    form.text = fr\n",
    "\n",
    "    transl = ET.SubElement(s, \"TRANSL\")\n",
    "    transl.set(\"xml:lang\", \"zh\")\n",
    "    transl.text = zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write somewhere\n",
    "tree = ET.ElementTree(root)\n",
    "ET.indent(tree, space=\"\\t\", level=0)\n",
    "tree.write('xml_check.xml', encoding=\"utf-8\") # change to path later"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
