{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml\n",
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "import PyPDF2 as ppdf\n",
    "import string\n",
    "import pickle\n",
    "from ratelimit import limits, sleep_and_retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vars\n",
    "URL = \"https://e-dictionary.ilrdf.org.tw/wsReDictionary.htm\"\n",
    "\n",
    "original_dict = {\n",
    "    2: 'Amis',\n",
    "    6: 'Atayal',\n",
    "    24: 'Paiwan',\n",
    "    22: 'Bunun',\n",
    "    38: 'Puyma',\n",
    "    28: 'Rukai',\n",
    "    35: 'Tsou',\n",
    "    13: 'Saisiyat',\n",
    "    42: 'Yami',\n",
    "    14: 'Thao',\n",
    "    34: 'Kavalan',\n",
    "    33: 'Truku',\n",
    "    43: 'Sakizaya',\n",
    "    16: 'Seediq',\n",
    "    37: 'Saaroa',\n",
    "    36: 'Kanakanavu'\n",
    "}\n",
    "\n",
    "# Create a new dictionary with keys and values swapped\n",
    "TRIBES = {v: k for k, v in original_dict.items()}\n",
    "NAMES = sorted([\n",
    "    'Amis',\n",
    "    'Atayal',\n",
    "    'Paiwan',\n",
    "    'Bunun',\n",
    "    'Puyma',\n",
    "    'Rukai',\n",
    "    'Tsou',\n",
    "    'Saisiyat',\n",
    "    'Yami',\n",
    "    'Thao',\n",
    "    'Kavalan',\n",
    "    'Truku',\n",
    "    'Sakizaya',\n",
    "    'Seediq',\n",
    "    'Saaroa',\n",
    "    'Kanakanavu'\n",
    "])\n",
    "\n",
    "NAME_TO_IDX = {name: i for i, name in enumerate(NAMES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rate vars\n",
    "# this mostly shouldn't matter since API times are already slow-ish\n",
    "RATE_LIMIT = 25\n",
    "RATE_PERIOD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWords(index): # scrape, do once -> provides wordlist\n",
    "    # Get path\n",
    "    folders = [folder for folder in os.listdir(os.getcwd()) if os.path.isdir(folder) and not folder[0] == \".\"]\n",
    "    folder = folders[index] # index\n",
    "    get_pdf = [file for file in os.listdir(folder)]\n",
    "    get_pdf = [file for file in get_pdf if re.search(r\".*\\.pdf\", file.lower())]\n",
    "    filepath = os.path.join(os.getcwd(), folder, get_pdf[0])\n",
    "\n",
    "    # Open it + scrape\n",
    "    all_tx = []\n",
    "    with open(filepath, 'rb') as f:\n",
    "        reader = ppdf.PdfReader(f)\n",
    "\n",
    "        for num in range(len(reader.pages)):\n",
    "            page = reader.pages[num]\n",
    "            all_tx.append(page.extract_text())\n",
    "\n",
    "    # Get words\n",
    "    fullstring = \"\"\n",
    "    for line in all_tx:\n",
    "        fullstring += line\n",
    "    \n",
    "    # Split + identify words\n",
    "    sep = fullstring.split(\"\\n\")\n",
    "    words = [word for word in sep if \"â˜…\" in word]\n",
    "    return [re.search(r\"^([a-z\\^A-Z']+)\", word).group(1) for word in words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @sleep_and_retry -- should not matter unless ratelimiting, if so uncomment\n",
    "# @limits(calls=RATE_LIMIT, period=RATE_PERIOD)\n",
    "def getData(tribeName, qw):\n",
    "    ask = {\n",
    "        \"FMT\": 1,\n",
    "        \"account\": \"E202403005\",\n",
    "        \"TribesCode\": TRIBES[tribeName],\n",
    "        \"qw\": qw\n",
    "    }\n",
    "\n",
    "    jsn_response = requests.post(URL, data=ask)\n",
    "    text = json.loads(jsn_response.text)\n",
    "    try:\n",
    "        assert jsn_response.status_code == 200\n",
    "        return text[\"GenericData\"]['DATA']\n",
    "    except:\n",
    "        return \"FAIL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSentences(entry): # helper for processRequest\n",
    "    word = entry[\"Name\"]\n",
    "    check = entry['Explanation']\n",
    "    fr, zh = '', ''\n",
    "\n",
    "    try:\n",
    "        if isinstance(check, list):\n",
    "            check = check[0] # it works\n",
    "            if isinstance(check['Sentence'], dict):\n",
    "                fr = check['Sentence']['Original']\n",
    "                zh = check['Sentence']['Chinese']\n",
    "\n",
    "            elif isinstance(check['Sentence'], list):\n",
    "                fr = check['Sentence'][0]['Original']\n",
    "                zh = check['Sentence'][0]['Chinese']\n",
    "        \n",
    "        elif isinstance(check, dict):\n",
    "            if isinstance(check['Sentence'], dict):\n",
    "                fr = check['Sentence']['Original']\n",
    "                zh = check['Sentence']['Chinese']\n",
    "\n",
    "            elif isinstance(check['Sentence'], list):\n",
    "                fr = check['Sentence'][0]['Original']\n",
    "                zh = check['Sentence'][0]['Chinese']\n",
    "        return {word: (fr, zh)}\n",
    "    except:\n",
    "        return \"FAIL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRequest(response): # response into dict of {word: (fr, zh)}\n",
    "    ret = {}\n",
    "    fails = []\n",
    "    if isinstance(response, list): # multiple entries\n",
    "        for i, entry in enumerate(response):\n",
    "            result = extractSentences(entry)\n",
    "            word = entry[\"Name\"]\n",
    "            if result == \"FAIL\":\n",
    "                print(word + \" has failed in extraction.\") # comment out if annoying \n",
    "                fails.append(word)\n",
    "            else:\n",
    "                ret.update(result)\n",
    "\n",
    "    elif isinstance(response, dict): # only 1 entry\n",
    "        result = extractSentences(response)\n",
    "        word = response[\"Name\"]\n",
    "        if result == \"FAIL\":\n",
    "            print(word + \" has failed in extraction.\") # comment out if annoying \n",
    "            fails.append(word)\n",
    "        else:\n",
    "            ret.update(result)\n",
    "        \n",
    "    return ret, fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path var + make folders\n",
    "base_path = os.path.join(os.getcwd(), '.PickleScrapes')\n",
    "\n",
    "for name in NAMES:\n",
    "    check = os.path.join(base_path, name)\n",
    "    if not os.path.exists(check):\n",
    "        os.mkdir(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change me each run\n",
    "scrapeTribe = 'Amis'\n",
    "\n",
    "# fetch wordlist\n",
    "words = set(getWords(NAME_TO_IDX[scrapeTribe]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at iteration 0: kalona\n",
      "Error occurred at iteration 2: maropayay\n"
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "word_sent_dict = {}\n",
    "fails = []\n",
    "seen = set()\n",
    "tribepath = os.path.join(base_path, scrapeTribe, scrapeTribe)\n",
    "\n",
    "for i, query in enumerate(words):\n",
    "    try:\n",
    "        if query in set():\n",
    "            pass\n",
    "        else:\n",
    "            seen.add(query)\n",
    "            response = getData(scrapeTribe, query) # change tribe\n",
    "            if response == 'FAIL':\n",
    "                fails.append(query)\n",
    "                pass\n",
    "\n",
    "            result, bad = processRequest(response)\n",
    "            fails.extend(bad)\n",
    "            if result == \"FAIL\":\n",
    "                fails.append(query)\n",
    "                pass\n",
    "\n",
    "            word_sent_dict.update(result)\n",
    "\n",
    "        if i % 500 == 0 or i == len(words) - 1:\n",
    "            with open(tribepath + '_ckpt_{0}.pkl'.format(i), 'w', encoding='utf8') as f: # change tribe\n",
    "                pickle.dump(word_sent_dict, f)\n",
    "            with open(tribepath + '_fails_{0}.pkl'.format(i), 'w', encoding='utf8') as f: # change tribe\n",
    "                pickle.dump(fails, f)\n",
    "    except:\n",
    "        print(f\"Error occurred at iteration {i}: {query}\")\n",
    "\n",
    "with open(tribepath + '_ckpt_END.pkl', 'wb') as f: # change tribe\n",
    "    pickle.dump(word_sent_dict, f)\n",
    "with open(tribepath + '_fails_END.pkl', 'wb') as f: # change tribe\n",
    "    pickle.dump(fails, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 170m runtime for 6k words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open archived files\n",
    "wsd_pickle = None\n",
    "with open(tribepath + '_fails_END.pkl', 'rb') as f: # change tribe\n",
    "    wsd_pickle = pickle.load(f)\n",
    "\n",
    "notgood = None\n",
    "with open(tribepath + '_fails_END.pkl', 'rb') as f: # change tribe\n",
    "    notgood = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML setup\n",
    "root = ET.Element(\"TEXT\")\n",
    "root.set(\"xml:lang\", \"fr\")\n",
    "root.set(\"id\", scrapeTribe) # change second arg to lang name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML adding\n",
    "for i, (word, sentpair) in enumerate(wsd_pickle.items()):\n",
    "    zh = sentpair[1]\n",
    "    fr = sentpair[0]\n",
    "\n",
    "    name = scrapeTribe + str(i) # change tribename\n",
    "    s = ET.SubElement(root, 'S')\n",
    "    s.set('id', name)\n",
    "\n",
    "    form = ET.SubElement(s, \"FORM\")\n",
    "    form.text = fr\n",
    "\n",
    "    transl = ET.SubElement(s, \"TRANSL\")\n",
    "    transl.set(\"xml:lang\", \"zh\")\n",
    "    transl.text = zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write somewhere\n",
    "tree = ET.ElementTree(root)\n",
    "ET.indent(tree, space=\"\\t\", level=0)\n",
    "writepath = os.path.join(os.getcwd(), '.PanglossXML')\n",
    "tree.write(os.path.join(writepath, '{0}.xml'.format(scrapeTribe)), encoding=\"utf-8\") # change to path later"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
